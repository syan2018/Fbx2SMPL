{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'egl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the device to run the body model on.\n",
    "comp_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "\n",
    "male_bm_path = './body_models/smplh/male/model.npz'\n",
    "male_dmpl_path = './body_models/dmpls/male/model.npz'\n",
    "\n",
    "female_bm_path = './body_models/smplh/female/model.npz'\n",
    "female_dmpl_path = './body_models/dmpls/female/model.npz'\n",
    "\n",
    "num_betas = 10 # number of body parameters\n",
    "num_dmpls = 8 # number of DMPL parameters\n",
    "\n",
    "male_bm = BodyModel(bm_fname=male_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=male_dmpl_path).to(comp_device)\n",
    "faces = c2c(male_bm.f)\n",
    "\n",
    "female_bm = BodyModel(bm_fname=female_bm_path, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=female_dmpl_path).to(comp_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "folders = []\n",
    "dataset_names = []\n",
    "for root, dirs, files in os.walk('./test_data'):\n",
    "#     print(root, dirs, files)\n",
    "#     for folder in dirs:\n",
    "#         folders.append(os.path.join(root, folder))\n",
    "    folders.append(root)\n",
    "    for name in files:\n",
    "        dataset_name = root.split('\\\\')[1]\n",
    "        if dataset_name not in dataset_names:\n",
    "            dataset_names.append(dataset_name)\n",
    "        paths.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root = './pose_data'\n",
    "save_folders = [folder.replace('./test_data', './pose_data') for folder in folders]\n",
    "for folder in save_folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "group_path = [[path for path in paths if name in path] for name in dataset_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_matrix = np.array([[1.0, 0.0, 0.0],\n",
    "                            [0.0, 0.0, 1.0],\n",
    "                            [0.0, 1.0, 0.0]])\n",
    "ex_fps = 20\n",
    "def amass_to_pose(src_path, save_path):\n",
    "    bdata = np.load(src_path, allow_pickle=True)\n",
    "    fps = 0\n",
    "    try:\n",
    "        fps = bdata['mocap_framerate']\n",
    "        frame_number = bdata['trans'].shape[0]\n",
    "    except:\n",
    "#         print(list(bdata.keys()))\n",
    "        return fps\n",
    "    \n",
    "    fId = 0 # frame id of the mocap sequence\n",
    "    pose_seq = []\n",
    "    if bdata['gender'] == 'male':\n",
    "        bm = male_bm\n",
    "    else:\n",
    "        bm = female_bm\n",
    "    down_sample = int(fps / ex_fps)\n",
    "#     print(frame_number)\n",
    "#     print(fps)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for fId in range(0, frame_number, down_sample):\n",
    "            root_orient = torch.Tensor(bdata['poses'][fId:fId+1, :3]).to(comp_device) # controls the global root orientation\n",
    "            pose_body = torch.Tensor(bdata['poses'][fId:fId+1, 3:66]).to(comp_device) # controls the body\n",
    "            pose_hand = torch.Tensor(bdata['poses'][fId:fId+1, 66:]).to(comp_device) # controls the finger articulation\n",
    "            betas = torch.Tensor(bdata['betas'][:10][np.newaxis]).to(comp_device) # controls the body shape\n",
    "            trans = torch.Tensor(bdata['trans'][fId:fId+1]).to(comp_device)    \n",
    "            body = bm(pose_body=pose_body, pose_hand=pose_hand, betas=betas, root_orient=root_orient)\n",
    "            joint_loc = body.Jtr[0] + trans\n",
    "            pose_seq.append(joint_loc.unsqueeze(0))\n",
    "    pose_seq = torch.cat(pose_seq, dim=0)\n",
    "    \n",
    "    pose_seq_np = pose_seq.detach().cpu().numpy()\n",
    "    pose_seq_np_n = np.dot(pose_seq_np, trans_matrix)\n",
    "    \n",
    "    np.save(save_path, pose_seq_np_n)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_path = group_path\n",
    "all_count = sum([len(paths) for paths in group_path])\n",
    "cur_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: test: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed / All (fps 30): 1/1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for paths in group_path:\n",
    "    dataset_name = paths[0].split('\\\\')[1]\n",
    "    pbar = tqdm(paths)\n",
    "    pbar.set_description('Processing: %s'%dataset_name)\n",
    "    fps = 0\n",
    "    for path in pbar:\n",
    "        save_path = path.replace('./test_data', './pose_data')\n",
    "        save_path = save_path[:-3] + 'npy'\n",
    "        fps = amass_to_pose(path, save_path)\n",
    "        \n",
    "    cur_count += len(paths)\n",
    "    print('Processed / All (fps %d): %d/%d'% (fps, cur_count, all_count) )\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs as cs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_left_right(data):\n",
    "    assert len(data.shape) == 3 and data.shape[-1] == 3\n",
    "    data = data.copy()\n",
    "    data[..., 0] *= -1\n",
    "    right_chain = [2, 5, 8, 11, 14, 17, 19, 21]\n",
    "    left_chain = [1, 4, 7, 10, 13, 16, 18, 20]\n",
    "    left_hand_chain = [22, 23, 24, 34, 35, 36, 25, 26, 27, 31, 32, 33, 28, 29, 30]\n",
    "    right_hand_chain = [43, 44, 45, 46, 47, 48, 40, 41, 42, 37, 38, 39, 49, 50, 51]\n",
    "    tmp = data[:, right_chain]\n",
    "    data[:, right_chain] = data[:, left_chain]\n",
    "    data[:, left_chain] = tmp\n",
    "    if data.shape[1] > 24:\n",
    "        tmp = data[:, right_hand_chain]\n",
    "        data[:, right_hand_chain] = data[:, left_hand_chain]\n",
    "        data[:, left_hand_chain] = tmp\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_path = './index copy.csv'\n",
    "save_dir = './joints'\n",
    "index_file = pd.read_csv(index_path)\n",
    "total_amount = index_file.shape[0]\n",
    "fps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 340.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(total_amount)):\n",
    "    source_path = index_file.loc[i]['source_path']\n",
    "    new_name = index_file.loc[i]['new_name']\n",
    "    data = np.load(source_path)\n",
    "    start_frame = index_file.loc[i]['start_frame']\n",
    "    end_frame = index_file.loc[i]['end_frame']\n",
    "    if 'humanact12' not in source_path:\n",
    "        if 'Eyes_Japan_Dataset' in source_path:\n",
    "            data = data[3*fps:]\n",
    "        if 'MPI_HDM05' in source_path:\n",
    "            data = data[3*fps:]\n",
    "        if 'TotalCapture' in source_path:\n",
    "            data = data[1*fps:]\n",
    "        if 'MPI_Limits' in source_path:\n",
    "            data = data[1*fps:]\n",
    "        if 'Transitions_mocap' in source_path:\n",
    "            data = data[int(0.5*fps):]\n",
    "        data = data[start_frame:end_frame]\n",
    "        data[..., 0] *= -1\n",
    "    \n",
    "    data_m = swap_left_right(data)\n",
    "#     save_path = pjoin(save_dir, )\n",
    "    np.save(pjoin(save_dir, new_name), data)\n",
    "    np.save(pjoin(save_dir, 'M'+new_name), data_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "\n",
    "from common.skeleton import Skeleton\n",
    "import numpy as np\n",
    "import os\n",
    "from common.quaternion import *\n",
    "from paramUtil import *\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_skeleton(positions, target_offset):\n",
    "    src_skel = Skeleton(n_raw_offsets, kinematic_chain, 'cpu')\n",
    "    src_offset = src_skel.get_offsets_joints(torch.from_numpy(positions[0]))\n",
    "    src_offset = src_offset.numpy()\n",
    "    tgt_offset = target_offset.numpy()\n",
    "    # print(src_offset)\n",
    "    # print(tgt_offset)\n",
    "    '''Calculate Scale Ratio as the ratio of legs'''\n",
    "    src_leg_len = np.abs(src_offset[l_idx1]).max() + np.abs(src_offset[l_idx2]).max()\n",
    "    tgt_leg_len = np.abs(tgt_offset[l_idx1]).max() + np.abs(tgt_offset[l_idx2]).max()\n",
    "\n",
    "    scale_rt = tgt_leg_len / src_leg_len\n",
    "    # print(scale_rt)\n",
    "    src_root_pos = positions[:, 0]\n",
    "    tgt_root_pos = src_root_pos * scale_rt\n",
    "\n",
    "    '''Inverse Kinematics'''\n",
    "    quat_params = src_skel.inverse_kinematics_np(positions, face_joint_indx)\n",
    "    # print(quat_params.shape)\n",
    "\n",
    "    '''Forward Kinematics'''\n",
    "    src_skel.set_offset(target_offset)\n",
    "    new_joints = src_skel.forward_kinematics_np(quat_params, tgt_root_pos)\n",
    "    return new_joints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(positions, feet_thre):\n",
    "    # (seq_len, joints_num, 3)\n",
    "    #     '''Down Sample'''\n",
    "    #     positions = positions[::ds_num]\n",
    "\n",
    "    '''Uniform Skeleton'''\n",
    "    positions = uniform_skeleton(positions, tgt_offsets)\n",
    "\n",
    "    '''Put on Floor'''\n",
    "    floor_height = positions.min(axis=0).min(axis=0)[1]\n",
    "    positions[:, :, 1] -= floor_height\n",
    "    #     print(floor_height)\n",
    "\n",
    "    #     plot_3d_motion(\"./positions_1.mp4\", kinematic_chain, positions, 'title', fps=20)\n",
    "\n",
    "    '''XZ at origin'''\n",
    "    root_pos_init = positions[0]\n",
    "    root_pose_init_xz = root_pos_init[0] * np.array([1, 0, 1])\n",
    "    positions = positions - root_pose_init_xz\n",
    "\n",
    "    # '''Move the first pose to origin '''\n",
    "    # root_pos_init = positions[0]\n",
    "    # positions = positions - root_pos_init[0]\n",
    "\n",
    "    '''All initially face Z+'''\n",
    "    r_hip, l_hip, sdr_r, sdr_l = face_joint_indx\n",
    "    across1 = root_pos_init[r_hip] - root_pos_init[l_hip]\n",
    "    across2 = root_pos_init[sdr_r] - root_pos_init[sdr_l]\n",
    "    across = across1 + across2\n",
    "    across = across / np.sqrt((across ** 2).sum(axis=-1))[..., np.newaxis]\n",
    "\n",
    "    # forward (3,), rotate around y-axis\n",
    "    forward_init = np.cross(np.array([[0, 1, 0]]), across, axis=-1)\n",
    "    # forward (3,)\n",
    "    forward_init = forward_init / np.sqrt((forward_init ** 2).sum(axis=-1))[..., np.newaxis]\n",
    "\n",
    "    #     print(forward_init)\n",
    "\n",
    "    target = np.array([[0, 0, 1]])\n",
    "    root_quat_init = qbetween_np(forward_init, target)\n",
    "    root_quat_init = np.ones(positions.shape[:-1] + (4,)) * root_quat_init\n",
    "\n",
    "    positions_b = positions.copy()\n",
    "\n",
    "    positions = qrot_np(root_quat_init, positions)\n",
    "\n",
    "    #     plot_3d_motion(\"./positions_2.mp4\", kinematic_chain, positions, 'title', fps=20)\n",
    "\n",
    "    '''New ground truth positions'''\n",
    "    global_positions = positions.copy()\n",
    "\n",
    "    # plt.plot(positions_b[:, 0, 0], positions_b[:, 0, 2], marker='*')\n",
    "    # plt.plot(positions[:, 0, 0], positions[:, 0, 2], marker='o', color='r')\n",
    "    # plt.xlabel('x')\n",
    "    # plt.ylabel('z')\n",
    "    # plt.axis('equal')\n",
    "    # plt.show()\n",
    "\n",
    "    \"\"\" Get Foot Contacts \"\"\"\n",
    "\n",
    "    def foot_detect(positions, thres):\n",
    "        velfactor, heightfactor = np.array([thres, thres]), np.array([3.0, 2.0])\n",
    "\n",
    "        feet_l_x = (positions[1:, fid_l, 0] - positions[:-1, fid_l, 0]) ** 2\n",
    "        feet_l_y = (positions[1:, fid_l, 1] - positions[:-1, fid_l, 1]) ** 2\n",
    "        feet_l_z = (positions[1:, fid_l, 2] - positions[:-1, fid_l, 2]) ** 2\n",
    "        #     feet_l_h = positions[:-1,fid_l,1]\n",
    "        #     feet_l = (((feet_l_x + feet_l_y + feet_l_z) < velfactor) & (feet_l_h < heightfactor)).astype(np.float)\n",
    "        feet_l = ((feet_l_x + feet_l_y + feet_l_z) < velfactor).astype(np.float32)\n",
    "\n",
    "        feet_r_x = (positions[1:, fid_r, 0] - positions[:-1, fid_r, 0]) ** 2\n",
    "        feet_r_y = (positions[1:, fid_r, 1] - positions[:-1, fid_r, 1]) ** 2\n",
    "        feet_r_z = (positions[1:, fid_r, 2] - positions[:-1, fid_r, 2]) ** 2\n",
    "        #     feet_r_h = positions[:-1,fid_r,1]\n",
    "        #     feet_r = (((feet_r_x + feet_r_y + feet_r_z) < velfactor) & (feet_r_h < heightfactor)).astype(np.float)\n",
    "        feet_r = (((feet_r_x + feet_r_y + feet_r_z) < velfactor)).astype(np.float32)\n",
    "        return feet_l, feet_r\n",
    "    #\n",
    "    feet_l, feet_r = foot_detect(positions, feet_thre)\n",
    "    # feet_l, feet_r = foot_detect(positions, 0.002)\n",
    "\n",
    "    '''Quaternion and Cartesian representation'''\n",
    "    r_rot = None\n",
    "\n",
    "    def get_rifke(positions):\n",
    "        '''Local pose'''\n",
    "        positions[..., 0] -= positions[:, 0:1, 0]\n",
    "        positions[..., 2] -= positions[:, 0:1, 2]\n",
    "        '''All pose face Z+'''\n",
    "        positions = qrot_np(np.repeat(r_rot[:, None], positions.shape[1], axis=1), positions)\n",
    "        return positions\n",
    "\n",
    "    def get_quaternion(positions):\n",
    "        skel = Skeleton(n_raw_offsets, kinematic_chain, \"cpu\")\n",
    "        # (seq_len, joints_num, 4)\n",
    "        quat_params = skel.inverse_kinematics_np(positions, face_joint_indx, smooth_forward=False)\n",
    "\n",
    "        '''Fix Quaternion Discontinuity'''\n",
    "        quat_params = qfix(quat_params)\n",
    "        # (seq_len, 4)\n",
    "        r_rot = quat_params[:, 0].copy()\n",
    "        #     print(r_rot[0])\n",
    "        '''Root Linear Velocity'''\n",
    "        # (seq_len - 1, 3)\n",
    "        velocity = (positions[1:, 0] - positions[:-1, 0]).copy()\n",
    "        #     print(r_rot.shape, velocity.shape)\n",
    "        velocity = qrot_np(r_rot[1:], velocity)\n",
    "        '''Root Angular Velocity'''\n",
    "        # (seq_len - 1, 4)\n",
    "        r_velocity = qmul_np(r_rot[1:], qinv_np(r_rot[:-1]))\n",
    "        quat_params[1:, 0] = r_velocity\n",
    "        # (seq_len, joints_num, 4)\n",
    "        return quat_params, r_velocity, velocity, r_rot\n",
    "\n",
    "    def get_cont6d_params(positions):\n",
    "        skel = Skeleton(n_raw_offsets, kinematic_chain, \"cpu\")\n",
    "        # (seq_len, joints_num, 4)\n",
    "        quat_params = skel.inverse_kinematics_np(positions, face_joint_indx, smooth_forward=True)\n",
    "\n",
    "        '''Quaternion to continuous 6D'''\n",
    "        cont_6d_params = quaternion_to_cont6d_np(quat_params)\n",
    "        # (seq_len, 4)\n",
    "        r_rot = quat_params[:, 0].copy()\n",
    "        #     print(r_rot[0])\n",
    "        '''Root Linear Velocity'''\n",
    "        # (seq_len - 1, 3)\n",
    "        velocity = (positions[1:, 0] - positions[:-1, 0]).copy()\n",
    "        #     print(r_rot.shape, velocity.shape)\n",
    "        velocity = qrot_np(r_rot[1:], velocity)\n",
    "        '''Root Angular Velocity'''\n",
    "        # (seq_len - 1, 4)\n",
    "        r_velocity = qmul_np(r_rot[1:], qinv_np(r_rot[:-1]))\n",
    "        # (seq_len, joints_num, 4)\n",
    "        return cont_6d_params, r_velocity, velocity, r_rot\n",
    "\n",
    "    cont_6d_params, r_velocity, velocity, r_rot = get_cont6d_params(positions)\n",
    "    positions = get_rifke(positions)\n",
    "\n",
    "    #     trejec = np.cumsum(np.concatenate([np.array([[0, 0, 0]]), velocity], axis=0), axis=0)\n",
    "    #     r_rotations, r_pos = recover_ric_glo_np(r_velocity, velocity[:, [0, 2]])\n",
    "\n",
    "    # plt.plot(positions_b[:, 0, 0], positions_b[:, 0, 2], marker='*')\n",
    "    # plt.plot(ground_positions[:, 0, 0], ground_positions[:, 0, 2], marker='o', color='r')\n",
    "    # plt.plot(trejec[:, 0], trejec[:, 2], marker='^', color='g')\n",
    "    # plt.plot(r_pos[:, 0], r_pos[:, 2], marker='s', color='y')\n",
    "    # plt.xlabel('x')\n",
    "    # plt.ylabel('z')\n",
    "    # plt.axis('equal')\n",
    "    # plt.show()\n",
    "\n",
    "    '''Root height'''\n",
    "    root_y = positions[:, 0, 1:2]\n",
    "\n",
    "    '''Root rotation and linear velocity'''\n",
    "    # (seq_len-1, 1) rotation velocity along y-axis\n",
    "    # (seq_len-1, 2) linear velovity on xz plane\n",
    "    r_velocity = np.arcsin(r_velocity[:, 2:3])\n",
    "    l_velocity = velocity[:, [0, 2]]\n",
    "    #     print(r_velocity.shape, l_velocity.shape, root_y.shape)\n",
    "    root_data = np.concatenate([r_velocity, l_velocity, root_y[:-1]], axis=-1)\n",
    "\n",
    "    '''Get Joint Rotation Representation'''\n",
    "    # (seq_len, (joints_num-1) *6) quaternion for skeleton joints\n",
    "    rot_data = cont_6d_params[:, 1:].reshape(len(cont_6d_params), -1)\n",
    "\n",
    "    '''Get Joint Rotation Invariant Position Represention'''\n",
    "    # (seq_len, (joints_num-1)*3) local joint position\n",
    "    ric_data = positions[:, 1:].reshape(len(positions), -1)\n",
    "\n",
    "    '''Get Joint Velocity Representation'''\n",
    "    # (seq_len-1, joints_num*3)\n",
    "    local_vel = qrot_np(np.repeat(r_rot[:-1, None], global_positions.shape[1], axis=1),\n",
    "                        global_positions[1:] - global_positions[:-1])\n",
    "    local_vel = local_vel.reshape(len(local_vel), -1)\n",
    "\n",
    "    data = root_data\n",
    "    data = np.concatenate([data, ric_data[:-1]], axis=-1)\n",
    "    data = np.concatenate([data, rot_data[:-1]], axis=-1)\n",
    "    #     print(data.shape, local_vel.shape)\n",
    "    data = np.concatenate([data, local_vel], axis=-1)\n",
    "    data = np.concatenate([data, feet_l, feet_r], axis=-1)\n",
    "\n",
    "    return data, global_positions, positions, l_velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover global angle and positions for rotation data\n",
    "# root_rot_velocity (B, seq_len, 1)\n",
    "# root_linear_velocity (B, seq_len, 2)\n",
    "# root_y (B, seq_len, 1)\n",
    "# ric_data (B, seq_len, (joint_num - 1)*3)\n",
    "# rot_data (B, seq_len, (joint_num - 1)*6)\n",
    "# local_velocity (B, seq_len, joint_num*3)\n",
    "# foot contact (B, seq_len, 4)\n",
    "def recover_root_rot_pos(data):\n",
    "    rot_vel = data[..., 0]\n",
    "    r_rot_ang = torch.zeros_like(rot_vel).to(data.device)\n",
    "    '''Get Y-axis rotation from rotation velocity'''\n",
    "    r_rot_ang[..., 1:] = rot_vel[..., :-1]\n",
    "    r_rot_ang = torch.cumsum(r_rot_ang, dim=-1)\n",
    "\n",
    "    r_rot_quat = torch.zeros(data.shape[:-1] + (4,)).to(data.device)\n",
    "    r_rot_quat[..., 0] = torch.cos(r_rot_ang)\n",
    "    r_rot_quat[..., 2] = torch.sin(r_rot_ang)\n",
    "\n",
    "    r_pos = torch.zeros(data.shape[:-1] + (3,)).to(data.device)\n",
    "    r_pos[..., 1:, [0, 2]] = data[..., :-1, 1:3]\n",
    "    '''Add Y-axis rotation to root position'''\n",
    "    r_pos = qrot(qinv(r_rot_quat), r_pos)\n",
    "\n",
    "    r_pos = torch.cumsum(r_pos, dim=-2)\n",
    "\n",
    "    r_pos[..., 1] = data[..., 3]\n",
    "    return r_rot_quat, r_pos\n",
    "\n",
    "\n",
    "def recover_from_rot(data, joints_num, skeleton):\n",
    "    r_rot_quat, r_pos = recover_root_rot_pos(data)\n",
    "\n",
    "    r_rot_cont6d = quaternion_to_cont6d(r_rot_quat)\n",
    "\n",
    "    start_indx = 1 + 2 + 1 + (joints_num - 1) * 3\n",
    "    end_indx = start_indx + (joints_num - 1) * 6\n",
    "    cont6d_params = data[..., start_indx:end_indx]\n",
    "    #     print(r_rot_cont6d.shape, cont6d_params.shape, r_pos.shape)\n",
    "    cont6d_params = torch.cat([r_rot_cont6d, cont6d_params], dim=-1)\n",
    "    cont6d_params = cont6d_params.view(-1, joints_num, 6)\n",
    "\n",
    "    positions = skeleton.forward_kinematics_cont6d(cont6d_params, r_pos)\n",
    "\n",
    "    return positions\n",
    "\n",
    "\n",
    "def recover_from_ric(data, joints_num):\n",
    "    r_rot_quat, r_pos = recover_root_rot_pos(data)\n",
    "    positions = data[..., 4:(joints_num - 1) * 3 + 4]\n",
    "    positions = positions.view(positions.shape[:-1] + (-1, 3))\n",
    "\n",
    "    '''Add Y-axis rotation to local joints'''\n",
    "    positions = qrot(qinv(r_rot_quat[..., None, :]).expand(positions.shape[:-1] + (4,)), positions)\n",
    "\n",
    "    '''Add root XZ to joints'''\n",
    "    positions[..., 0] += r_pos[..., 0:1]\n",
    "    positions[..., 2] += r_pos[..., 2:3]\n",
    "\n",
    "    '''Concate root and joints'''\n",
    "    positions = torch.cat([r_pos.unsqueeze(-2), positions], dim=-2)\n",
    "\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 30.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clips: 2, Frames: 138, Duration: 0.115000m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The given data is used to double check if you are on the right track.\n",
    "reference1 = np.load('./HumanML3D/new_joints/012314.npy')\n",
    "reference2 = np.load('./HumanML3D/new_joint_vecs/012314.npy')\n",
    "\n",
    "'''\n",
    "For HumanML3D Dataset\n",
    "'''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_id = \"111111\"\n",
    "    # Lower legs\n",
    "    l_idx1, l_idx2 = 5, 8\n",
    "    # Right/Left foot\n",
    "    fid_r, fid_l = [8, 11], [7, 10]\n",
    "    # Face direction, r_hip, l_hip, sdr_r, sdr_l\n",
    "    face_joint_indx = [2, 1, 17, 16]\n",
    "    # l_hip, r_hip\n",
    "    r_hip, l_hip = 2, 1\n",
    "    joints_num = 22\n",
    "    # ds_num = 8\n",
    "    data_dir = './joints/'\n",
    "    save_dir1 = './HumanML3D/new_joints/'\n",
    "    save_dir2 = './HumanML3D/new_joint_vecs/'\n",
    "    \n",
    "    os.makedirs(save_dir1, exist_ok=True)\n",
    "    os.makedirs(save_dir2, exist_ok=True)\n",
    "\n",
    "    n_raw_offsets = torch.from_numpy(t2m_raw_offsets)\n",
    "    kinematic_chain = t2m_kinematic_chain\n",
    "\n",
    "    # Get offsets of target skeleton\n",
    "    example_data = np.load(os.path.join(data_dir, example_id + '.npy'))\n",
    "    example_data = example_data.reshape(len(example_data), -1, 3)\n",
    "    example_data = torch.from_numpy(example_data)\n",
    "    tgt_skel = Skeleton(n_raw_offsets, kinematic_chain, 'cpu')\n",
    "    # (joints_num, 3)\n",
    "    tgt_offsets = tgt_skel.get_offsets_joints(example_data[0])\n",
    "    # print(tgt_offsets)\n",
    "\n",
    "    source_list = os.listdir(data_dir)\n",
    "    frame_num = 0\n",
    "    for source_file in tqdm(source_list):\n",
    "        source_data = np.load(os.path.join(data_dir, source_file))[:, :joints_num]\n",
    "        try:\n",
    "            data, ground_positions, positions, l_velocity = process_file(source_data, 0.002)\n",
    "            rec_ric_data = recover_from_ric(torch.from_numpy(data).unsqueeze(0).float(), joints_num)\n",
    "            np.save(pjoin(save_dir1, source_file), rec_ric_data.squeeze().numpy())\n",
    "            np.save(pjoin(save_dir2, source_file), data)\n",
    "            frame_num += data.shape[0]\n",
    "        except Exception as e:\n",
    "            print(source_file)\n",
    "            print(e)\n",
    "#         print(source_file)\n",
    "#         break\n",
    "\n",
    "    print('Total clips: %d, Frames: %d, Duration: %fm' %\n",
    "          (len(source_list), frame_num, frame_num / 20 / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "def plot_3d_motion(save_path, kinematic_tree, joints, title, figsize=(10, 10), fps=120, radius=4,elev=120):\n",
    "#     matplotlib.use('Agg')\n",
    "\n",
    "    title_sp = title.split(' ')\n",
    "    if len(title_sp) > 10:\n",
    "        title = '\\n'.join([' '.join(title_sp[:10]), ' '.join(title_sp[10:])])\n",
    "    def init():\n",
    "        ax.set_xlim3d([-radius / 2, radius / 2])\n",
    "        ax.set_ylim3d([0, radius])\n",
    "        ax.set_zlim3d([0, radius])\n",
    "        # print(title)\n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        ax.grid(b=False)\n",
    "\n",
    "\n",
    "\n",
    "    def plot_xzPlane(minx, maxx, miny, minz, maxz):\n",
    "        ## Plot a plane XZ\n",
    "        verts = [\n",
    "            [minx, miny, minz],\n",
    "            [minx, miny, maxz],\n",
    "            [maxx, miny, maxz],\n",
    "            [maxx, miny, minz]\n",
    "        ]\n",
    "        xz_plane = Poly3DCollection([verts])\n",
    "        xz_plane.set_facecolor((0.5, 0.5, 0.5, 0.5))\n",
    "        ax.add_collection3d(xz_plane)\n",
    "\n",
    "    #         return ax\n",
    "\n",
    "    # (seq_len, joints_num, 3)\n",
    "    data = joints.copy().reshape(len(joints), -1, 3)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = p3.Axes3D(fig)\n",
    "    init()\n",
    "    MINS = data.min(axis=0).min(axis=0)\n",
    "    MAXS = data.max(axis=0).max(axis=0)\n",
    "    colors = ['red', 'blue', 'black', 'red', 'blue',  \n",
    "              'darkblue', 'darkblue', 'darkblue', 'darkblue', 'darkblue',\n",
    "             'darkred', 'darkred','darkred','darkred','darkred']\n",
    "    frame_number = data.shape[0]\n",
    "    #     print(data.shape)\n",
    "\n",
    "    height_offset = MINS[1]\n",
    "    data[:, :, 1] -= height_offset\n",
    "    trajec = data[:, 0, [0, 2]]\n",
    "    \n",
    "    data[..., 0] -= data[:, 0:1, 0]\n",
    "    data[..., 2] -= data[:, 0:1, 2]\n",
    "\n",
    "    #     print(trajec.shape)\n",
    "\n",
    "    def update(index):\n",
    "        #         print(index)\n",
    "        ax.lines = []\n",
    "        ax.collections = []\n",
    "        # ax.view_init(elev=120, azim=-90)\n",
    "        ax.view_init(elev=elev, azim=-90)\n",
    "        ax.dist = 7.5\n",
    "        #         ax =\n",
    "        plot_xzPlane(MINS[0]-trajec[index, 0], MAXS[0]-trajec[index, 0], 0, MINS[2]-trajec[index, 1], MAXS[2]-trajec[index, 1])\n",
    "#         ax.scatter(data[index, :22, 0], data[index, :22, 1], data[index, :22, 2], color='black', s=3)\n",
    "        \n",
    "        if index > 1:\n",
    "            ax.plot3D(trajec[:index, 0]-trajec[index, 0], np.zeros_like(trajec[:index, 0]), trajec[:index, 1]-trajec[index, 1], linewidth=1.0,\n",
    "                      color='blue')\n",
    "        #             ax = plot_xzPlane(ax, MINS[0], MAXS[0], 0, MINS[2], MAXS[2])\n",
    "        \n",
    "        \n",
    "        for i, (chain, color) in enumerate(zip(kinematic_tree, colors)):\n",
    "#             print(color)\n",
    "            if i < 5:\n",
    "                linewidth = 4.0\n",
    "            else:\n",
    "                linewidth = 2.0\n",
    "            ax.plot3D(data[index, chain, 0], data[index, chain, 1], data[index, chain, 2], linewidth=linewidth, color=color)\n",
    "        #         print(trajec[:index, 0].shape)\n",
    "\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=frame_number, interval=1000/fps, repeat=False)\n",
    "\n",
    "    ani.save(save_path, fps=fps)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = './HumanML3D/new_joints/'\n",
    "tgt_ani_dir = \"./HumanML3D/animations/\"\n",
    "\n",
    "kinematic_chain = [[0, 2, 5, 8, 11], [0, 1, 4, 7, 10], [0, 3, 6, 9, 12, 15], [9, 14, 17, 19, 21], [9, 13, 16, 18, 20]]\n",
    "os.makedirs(tgt_ani_dir, exist_ok=True)\n",
    "\n",
    "npy_files = os.listdir(src_dir)\n",
    "npy_files = sorted(npy_files)\n",
    "# npy_files = npy_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.50it/s]\n"
     ]
    }
   ],
   "source": [
    "for npy_file in tqdm(npy_files):\n",
    "    data = np.load(pjoin(src_dir, npy_file))\n",
    "    save_path = pjoin(tgt_ani_dir, npy_file[:-3] + 'mp4')\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "    #   You may set the title on your own.\n",
    "    plot_3d_motion(save_path, kinematic_chain, data, title=\"None\", fps=20, radius=4, elev=120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
